{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "conda-env-opencv-py",
   "display_name": "Python [conda env:opencv]",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pyzbar.pyzbar as pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('qr/0007.bmp')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# img = cv2.resize(img, (0, 0), fx=2.5, fy=2.5)\n",
    "barcodes=pyzbar.decode(img)\n",
    "print(barcodes)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_img = np.fft.fft2(img)\n",
    "r, c = img.shape\n",
    "fft_img = np.fft.fftshift(fft_img)\n",
    "\n",
    "show_img = np.abs(fft_img)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((201, 201))\n",
    "for i in range(D.shape[0]):\n",
    "    for j in range(D.shape[1]):\n",
    "        D[i, j] = np.sqrt((i-100)**2+(j-100)**2)\n",
    "D[100, 100]=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_img = np.fft.fft2(img)\n",
    "r, c = img.shape\n",
    "fft_img = np.fft.fftshift(fft_img)\n",
    "\n",
    "D0, n = 10, 5\n",
    "trunc_D = D[100-r//2:100-r//2+r, 100-c//2:100-c//2+c]\n",
    "H = 1 / (1 + (D0/trunc_D)**2)\n",
    "H[r//2, c//2]=1\n",
    "\n",
    "filtered_img = H * fft_img\n",
    "filtered_img = np.fft.ifft2(filtered_img)\n",
    "filtered_img = np.abs(filtered_img)\n",
    "\n",
    "filtered_img = np.around(np.abs(filtered_img)).astype(np.uint8)\n",
    "\n",
    "barcodes=pyzbar.decode(filtered_img)\n",
    "print(barcodes)\n",
    "plt.imshow(filtered_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(filtered_img, 40, 150)\n",
    "plt.imshow(canny, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 21))\n",
    "morphed = cv2.morphologyEx(filtered_img, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "barcodes=pyzbar.decode(morphed)\n",
    "print(barcodes)\n",
    "plt.imshow(morphed, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrs, _ = cv2.threshold(filtered_img, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "output2 = filtered_img.copy()\n",
    "for i in range(output.shape[0]):\n",
    "    for j in range(output.shape[1]):\n",
    "        if output2[i][j] < thrs:\n",
    "            output2[i][j] //= 3\n",
    "        # else:\n",
    "        #     output2[i][j] = min(int(output2[i][j]*1.5), 255)\n",
    "barcodes=pyzbar.decode(output2)\n",
    "print(thrs, barcodes)\n",
    "plt.imshow(output2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.adaptiveThreshold(output, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 5)\n",
    "barcodes=pyzbar.decode(test)\n",
    "print(barcodes)\n",
    "plt.imshow(test, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_img = np.fft.fft2(output)\n",
    "r1, c1 = output.shape\n",
    "fft_img = np.fft.fftshift(fft_img)\n",
    "\n",
    "D0, n = 3, 5\n",
    "trunc_D = D[100-r1//2:100-r1//2+r1, 100-c1//2:100-c1//2+c1]\n",
    "H = 1 / (1 + (D0/trunc_D)**2)\n",
    "H[r1//2, c1//2]=1\n",
    "\n",
    "filtered_img = H * fft_img\n",
    "filtered_img = np.fft.ifft2(filtered_img)\n",
    "filtered_img = np.real(filtered_img)\n",
    "\n",
    "filtered_img = np.around(np.abs(filtered_img)).astype(np.uint8)\n",
    "\n",
    "barcodes=pyzbar.decode(filtered_img)\n",
    "print(barcodes)\n",
    "plt.imshow(filtered_img, cmap='gray')"
   ]
  },
  {
   "source": [
    "分割线"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_img = np.fft.fft2(output)\n",
    "r2, c2 = output.shape\n",
    "fft_img = np.fft.fftshift(fft_img)\n",
    "\n",
    "D0, n = 3, 5\n",
    "trunc_D = D[100-r1//2:100-r1//2+r1, 100-c1//2:100-c1//2+c1]\n",
    "H = 1 / (1 + (D0/trunc_D)**2)\n",
    "H[r1//2, c1//2]=1\n",
    "\n",
    "filtered_img = H * fft_img\n",
    "filtered_img = np.fft.ifft2(filtered_img)\n",
    "filtered_img = np.real(filtered_img)\n",
    "\n",
    "filtered_img = np.around(np.abs(filtered_img)).astype(np.uint8)\n",
    "\n",
    "barcodes=pyzbar.decode(filtered_img)\n",
    "print(barcodes)\n",
    "plt.imshow(filtered_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 255 - img\n",
    "blur = cv2.medianBlur(img, 1)\n",
    "plt.imshow(blur, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\r\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\r\n",
    "plt.imshow(morphed, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 255 - cv2.subtract(img, morphed)\n",
    "barcodes=pyzbar.decode(output)\n",
    "print(barcodes)\n",
    "plt.imshow(output, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "# morph_img = cv2.morphologyEx(output, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# test = cv2.adaptiveThreshold(morph_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 2)\n",
    "# plt.imshow(morph_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny = cv2.Canny(test, 40, 150)\n",
    "\n",
    "# contour_img = cv2.cvtColor(output, cv2.COLOR_GRAY2BGR)\n",
    "# contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# contour_img = cv2.drawContours(contour_img, contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "# plt.imshow(contour_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_contour ,max_area = 0, 0\n",
    "# for contour in contours:\n",
    "#     tmp = cv2.contourArea(contour)\n",
    "#     if tmp > max_area:\n",
    "#         max_contour, max_area = contour, tmp\n",
    "# print(max_contour.shape)\n",
    "# max_contour = max_contour[::-1, :, :]\n",
    "\n",
    "# # robustness：如果不是4怎么办   0.02来自于网络\n",
    "# poly_contour = cv2.approxPolyDP(max_contour, 0.02 * cv2.arcLength(max_contour, True), True)\n",
    "\n",
    "# points = poly_contour.squeeze()\n",
    "# # assert(len(poly_contour) == 4)\n",
    "# print(poly_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = np.cross(points[1]-points[0], points[2]-points[1])\n",
    "# if c > 0:   # 修正为右旋标价\n",
    "#     points = points[::-1, :]\n",
    "\n",
    "# len1 = np.linalg.norm(points[0] - points[1])\n",
    "# len2 = np.linalg.norm(points[1] - points[2])\n",
    "# if len1 >= len2:    # 短边优先\n",
    "#     points = np.roll(points, 1, axis=0)\n",
    "\n",
    "# if points[0][0] > points[2][0]: # y值小的优先\n",
    "#     points = np.roll(points, 2, axis=0)\n",
    "\n",
    "# outer_x, outer_y = 10, 10\n",
    "# shape_x, shape_y = 105, 105\n",
    "\n",
    "# N = np.array([[outer_x, outer_y], [outer_x, shape_y - outer_y], \n",
    "#             [shape_x - outer_x, shape_y - outer_y], [shape_x - outer_x, outer_y]])\n",
    "# mat = cv2.getPerspectiveTransform(points.astype(np.float32), N.astype(np.float32))\n",
    "# output1 = cv2.warpPerspective(output, mat, (shape_x, shape_y), borderValue=255)\n",
    "# plt.imshow(output1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = output1\n",
    "\n",
    "laplacian = cv2.Laplacian(output, -1)\n",
    "new_img =cv2.subtract(output, laplacian)\n",
    "barcodes=pyzbar.decode(new_img)\n",
    "print(barcodes)\n",
    "plt.imshow(new_img, cmap='gray')\n",
    "\n",
    "output = new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.adaptiveThreshold(new_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "barcodes=pyzbar.decode(test)\n",
    "print(barcodes)\n",
    "plt.imshow(test, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = filtered_img\n",
    "\n",
    "for i in range(127, 256):  #粗暴的阈值处理（可能先通过某种算法调整对比度）\n",
    "    _, output2 = cv2.threshold(new_img, i, 255, cv2.THRESH_BINARY)\n",
    "    barcodes=pyzbar.decode(output2)\n",
    "    if len(barcodes) != 0:\n",
    "        break\n",
    "# _, output2 = cv2.threshold(new_img, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "print(i, barcodes)\n",
    "plt.imshow(output2, cmap='gray')"
   ]
  },
  {
   "source": [
    "### 一个简单的汇总"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_img(old_img):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "    morph_img = cv2.morphologyEx(old_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    test = cv2.adaptiveThreshold(morph_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 2)\n",
    "    canny = cv2.Canny(test, 40, 150)\n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    max_contour ,max_area = 0, 0\n",
    "    for contour in contours:\n",
    "        tmp = cv2.contourArea(contour)\n",
    "        if tmp > max_area:\n",
    "            max_contour, max_area = contour, tmp\n",
    "    \n",
    "    max_contour = max_contour[::-1, :, :]\n",
    "    poly_contour = cv2.approxPolyDP(max_contour, 0.02 * cv2.arcLength(max_contour, True), True)\n",
    "    points = poly_contour.squeeze()\n",
    "    if len(poly_contour) != 4:\n",
    "        return None\n",
    "\n",
    "    c = np.cross(points[1]-points[0], points[2]-points[1])\n",
    "    if c > 0:   # 修正为右旋标价\n",
    "        points = points[::-1, :]\n",
    "\n",
    "    len1 = np.linalg.norm(points[0] - points[1])\n",
    "    len2 = np.linalg.norm(points[1] - points[2])\n",
    "    if len1 >= len2:    # 短边优先\n",
    "        points = np.roll(points, 1, axis=0)\n",
    "\n",
    "    if points[0][0] > points[2][0]: # y值小的优先\n",
    "        points = np.roll(points, 2, axis=0)\n",
    "\n",
    "    outer_x, outer_y = 10, 10\n",
    "    shape_x, shape_y = 105, 105\n",
    "\n",
    "    N = np.array([[outer_x, outer_y], [outer_x, shape_y - outer_y], \n",
    "                [shape_x - outer_x, shape_y - outer_y], [shape_x - outer_x, outer_y]])\n",
    "    mat = cv2.getPerspectiveTransform(points.astype(np.float32), N.astype(np.float32))\n",
    "    return cv2.warpPerspective(output, mat, (shape_x, shape_y), borderValue=255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att2(img):\n",
    "    fft_img = np.fft.fft2(img)\n",
    "    r, c = img.shape\n",
    "    fft_img = np.fft.fftshift(fft_img)\n",
    "\n",
    "    D0, n = 10, 5\n",
    "    trunc_D = D[100-r//2:100-r//2+r, 100-c//2:100-c//2+c]\n",
    "    H = 1 / (1 + (D0/trunc_D)**2)\n",
    "    H[r//2, c//2]=1\n",
    "\n",
    "    filtered_img = H * fft_img\n",
    "    filtered_img = np.fft.ifft2(filtered_img)\n",
    "    filtered_img = np.real(filtered_img)\n",
    "\n",
    "    filtered_img = np.around(np.abs(filtered_img)).astype(np.uint8)\n",
    "\n",
    "    barcodes=pyzbar.decode(filtered_img)\n",
    "    if len(barcodes) > 0:\n",
    "        return 5, barcodes[0].data.decode('utf-8')\n",
    "    \n",
    "    test = cv2.adaptiveThreshold(filtered_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "    barcodes=pyzbar.decode(test)\n",
    "    if len(barcodes) > 0:\n",
    "        return 5, barcodes[0].data.decode('utf-8')\n",
    "    test = cv2.adaptiveThreshold(filtered_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "    barcodes=pyzbar.decode(test)\n",
    "    if len(barcodes) > 0:\n",
    "        return 5, barcodes[0].data.decode('utf-8')\n",
    "\n",
    "    for i in range(127, 256):  #粗暴的阈值处理（可能先通过某种算法调整对比度）\n",
    "        _, output2 = cv2.threshold(filtered_img, i, 255, cv2.THRESH_BINARY)\n",
    "        barcodes=pyzbar.decode(output2)\n",
    "        if len(barcodes) != 0:\n",
    "            return 5, barcodes[0].data.decode('utf-8')\n",
    "    return -1, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog_qr(img, not_continue=False):\n",
    "    barcodes=pyzbar.decode(img)\n",
    "    if len(barcodes) > 0:\n",
    "        return 0, barcodes[0].data.decode('utf-8')\n",
    "    \n",
    "    img = 255 - img\n",
    "    # blur = cv2.medianBlur(img, 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    output = 255 - cv2.subtract(img, morphed)\n",
    "    barcodes=pyzbar.decode(output)\n",
    "    if len(barcodes) > 0:\n",
    "        return 1, barcodes[0].data.decode('utf-8')\n",
    "    \n",
    "\n",
    "    for att in range(3):\n",
    "        laplacian = cv2.Laplacian(output, -1)\n",
    "        new_img =cv2.subtract(output, laplacian)\n",
    "        barcodes=pyzbar.decode(new_img)\n",
    "        if len(barcodes) > 0:\n",
    "            return 2, barcodes[0].data.decode('utf-8')\n",
    "        \n",
    "        test = cv2.adaptiveThreshold(new_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "        barcodes=pyzbar.decode(test)\n",
    "        if len(barcodes) > 0:\n",
    "            return 3, barcodes[0].data.decode('utf-8')\n",
    "        test = cv2.adaptiveThreshold(new_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "        barcodes=pyzbar.decode(test)\n",
    "        if len(barcodes) > 0:\n",
    "            return 3, barcodes[0].data.decode('utf-8')\n",
    "        \n",
    "        if not_continue:\n",
    "            return -1, ''\n",
    "\n",
    "        for i in range(127, 256):  #粗暴的阈值处理（可能先通过某种算法调整对比度）\n",
    "            _, output2 = cv2.threshold(new_img, i, 255, cv2.THRESH_BINARY)\n",
    "            barcodes=pyzbar.decode(output2)\n",
    "            if len(barcodes) != 0:\n",
    "                return 4, barcodes[0].data.decode('utf-8')\n",
    "        if not_continue:\n",
    "            return -1, ''\n",
    "        else:\n",
    "            img = cv2.resize(img, (0, 0), fx=2.5, fy=2.5)\n",
    "            return recog_qr(img, True)\n",
    "            \n",
    "            # output = fix_img(new_img)\n",
    "            # if output is None:\n",
    "            #     return att2(img)\n",
    "            # else:\n",
    "            #     return att2(output)\n",
    "    # return att2(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qr(img):\n",
    "    status, content = recog_qr(img, False)\n",
    "    if status != -1:\n",
    "        return status, content\n",
    "    \n",
    "    for rate in np.arange(0.8, 1, 0.01):\n",
    "        for divide in np.arange(0.25, 0.5, 0.05):\n",
    "            r, c = img.shape\n",
    "            crop_x = int(c * divide)\n",
    "            left_img = img[:, :crop_x]\n",
    "            right_img = img[:, crop_x:]\n",
    "            rl, cl = left_img.shape\n",
    "            left_img2 = cv2.resize(left_img, (int(cl*rate),  rl))\n",
    "            fit_img = np.hstack([left_img2, right_img])\n",
    "\n",
    "            status, content = recog_qr(fit_img, True)\n",
    "            if status != -1:\n",
    "                return status, content\n",
    "    return -1, ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'qr'\n",
    "output_file = 'predictions.txt'\n",
    "counter = [0, 0, 0, 0, 0]\n",
    "\n",
    "D = np.zeros((201, 201))\n",
    "for i in range(D.shape[0]):\n",
    "    for j in range(D.shape[1]):\n",
    "        D[i, j] = np.sqrt((i-100)**2+(j-100)**2)\n",
    "D[100, 100]=1e-3\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for file_name in tqdm(os.listdir(input_path)):\n",
    "        img = cv2.imread(os.path.join(input_path, file_name))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # img = cv2.resize(img, (0, 0), fx=2.5, fy=2.5)\n",
    "        status, result = process_qr(img)\n",
    "        f.write('{} {}\\n'.format(file_name, result))\n",
    "        if status != -1:\n",
    "            counter[status] += 1\n",
    "\n",
    "total = sum(counter)\n",
    "print()\n",
    "print('Sum*', 'Base', 'T-hat', 'lapla', 'athrs', 'thrs',, sep='\\t')\n",
    "print(total, *counter, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}