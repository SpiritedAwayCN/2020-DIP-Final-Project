{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "conda-env-opencv-py",
   "display_name": "Python [conda env:opencv]",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pyzbar.pyzbar as pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('qr/0007.bmp')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "barcodes=pyzbar.decode(img)\n",
    "print(barcodes)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 255 - img\n",
    "blur = cv2.medianBlur(img, 1)\n",
    "plt.imshow(blur, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\r\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\r\n",
    "plt.imshow(morphed, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 255 - cv2.subtract(img, morphed)\n",
    "barcodes=pyzbar.decode(output)\n",
    "print(barcodes)\n",
    "plt.imshow(output, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "# morph_img = cv2.morphologyEx(output, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# test = cv2.adaptiveThreshold(morph_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 2)\n",
    "# plt.imshow(morph_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny = cv2.Canny(test, 40, 150)\n",
    "\n",
    "# contour_img = cv2.cvtColor(output, cv2.COLOR_GRAY2BGR)\n",
    "# contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# contour_img = cv2.drawContours(contour_img, contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "# plt.imshow(contour_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_contour ,max_area = 0, 0\n",
    "# for contour in contours:\n",
    "#     tmp = cv2.contourArea(contour)\n",
    "#     if tmp > max_area:\n",
    "#         max_contour, max_area = contour, tmp\n",
    "# print(max_contour.shape)\n",
    "# max_contour = max_contour[::-1, :, :]\n",
    "\n",
    "# # robustness：如果不是4怎么办   0.02来自于网络\n",
    "# poly_contour = cv2.approxPolyDP(max_contour, 0.02 * cv2.arcLength(max_contour, True), True)\n",
    "\n",
    "# points = poly_contour.squeeze()\n",
    "# # assert(len(poly_contour) == 4)\n",
    "# print(poly_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = np.cross(points[1]-points[0], points[2]-points[1])\n",
    "# if c > 0:   # 修正为右旋标价\n",
    "#     points = points[::-1, :]\n",
    "\n",
    "# len1 = np.linalg.norm(points[0] - points[1])\n",
    "# len2 = np.linalg.norm(points[1] - points[2])\n",
    "# if len1 >= len2:    # 短边优先\n",
    "#     points = np.roll(points, 1, axis=0)\n",
    "\n",
    "# if points[0][0] > points[2][0]: # y值小的优先\n",
    "#     points = np.roll(points, 2, axis=0)\n",
    "\n",
    "# outer_x, outer_y = 10, 10\n",
    "# shape_x, shape_y = 105, 105\n",
    "\n",
    "# N = np.array([[outer_x, outer_y], [outer_x, shape_y - outer_y], \n",
    "#             [shape_x - outer_x, shape_y - outer_y], [shape_x - outer_x, outer_y]])\n",
    "# mat = cv2.getPerspectiveTransform(points.astype(np.float32), N.astype(np.float32))\n",
    "# output1 = cv2.warpPerspective(output, mat, (shape_x, shape_y), borderValue=255)\n",
    "# plt.imshow(output1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = output1\n",
    "\n",
    "laplacian = cv2.Laplacian(output, -1)\n",
    "new_img =cv2.subtract(output, laplacian)\n",
    "barcodes=pyzbar.decode(new_img)\n",
    "print(barcodes)\n",
    "plt.imshow(new_img, cmap='gray')\n",
    "\n",
    "output = new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.adaptiveThreshold(new_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "barcodes=pyzbar.decode(test)\n",
    "print(barcodes)\n",
    "plt.imshow(test, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(127, 255):  #粗暴的阈值处理（可能先通过某种算法调整对比度）\n",
    "    _, output2 = cv2.threshold(new_img, i, 255, cv2.THRESH_BINARY)\n",
    "    barcodes=pyzbar.decode(output2)\n",
    "    if len(barcodes) != 0:\n",
    "        break\n",
    "# _, output2 = cv2.threshold(new_img, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "print(i, barcodes)\n",
    "plt.imshow(output2, cmap='gray')"
   ]
  },
  {
   "source": [
    "### 一个简单的汇总"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_img(old_img):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "    morph_img = cv2.morphologyEx(old_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    test = cv2.adaptiveThreshold(morph_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 2)\n",
    "    canny = cv2.Canny(test, 40, 150)\n",
    "\n",
    "    max_contour ,max_area = 0, 0\n",
    "    for contour in contours:\n",
    "        tmp = cv2.contourArea(contour)\n",
    "        if tmp > max_area:\n",
    "            max_contour, max_area = contour, tmp\n",
    "    \n",
    "    max_contour = max_contour[::-1, :, :]\n",
    "    poly_contour = cv2.approxPolyDP(max_contour, 0.02 * cv2.arcLength(max_contour, True), True)\n",
    "    points = poly_contour.squeeze()\n",
    "    if len(poly_contour) != 4:\n",
    "        return None\n",
    "\n",
    "    c = np.cross(points[1]-points[0], points[2]-points[1])\n",
    "    if c > 0:   # 修正为右旋标价\n",
    "        points = points[::-1, :]\n",
    "\n",
    "    len1 = np.linalg.norm(points[0] - points[1])\n",
    "    len2 = np.linalg.norm(points[1] - points[2])\n",
    "    if len1 >= len2:    # 短边优先\n",
    "        points = np.roll(points, 1, axis=0)\n",
    "\n",
    "    if points[0][0] > points[2][0]: # y值小的优先\n",
    "        points = np.roll(points, 2, axis=0)\n",
    "\n",
    "    outer_x, outer_y = 10, 10\n",
    "    shape_x, shape_y = 105, 105\n",
    "\n",
    "    N = np.array([[outer_x, outer_y], [outer_x, shape_y - outer_y], \n",
    "                [shape_x - outer_x, shape_y - outer_y], [shape_x - outer_x, outer_y]])\n",
    "    mat = cv2.getPerspectiveTransform(points.astype(np.float32), N.astype(np.float32))\n",
    "    return cv2.warpPerspective(output, mat, (shape_x, shape_y), borderValue=255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog_qr(img):\n",
    "    barcodes=pyzbar.decode(img)\n",
    "    if len(barcodes) > 0:\n",
    "        return 0, barcodes[0].data.decode('utf-8')\n",
    "    \n",
    "    img = 255 - img\n",
    "    blur = cv2.medianBlur(img, 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    output = 255 - cv2.subtract(img, morphed)\n",
    "    barcodes=pyzbar.decode(output)\n",
    "    if len(barcodes) > 0:\n",
    "        return 1, barcodes[0].data.decode('utf-8')\n",
    "    \n",
    "\n",
    "    for att in range(3):\n",
    "        laplacian = cv2.Laplacian(output, -1)\n",
    "        new_img =cv2.subtract(output, laplacian)\n",
    "        barcodes=pyzbar.decode(new_img)\n",
    "        if len(barcodes) > 0:\n",
    "            return 2, barcodes[0].data.decode('utf-8')\n",
    "        \n",
    "        test = cv2.adaptiveThreshold(new_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "        barcodes=pyzbar.decode(test)\n",
    "        if len(barcodes) > 0:\n",
    "            return 3, barcodes[0].data.decode('utf-8')\n",
    "        test = cv2.adaptiveThreshold(new_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "        barcodes=pyzbar.decode(test)\n",
    "        if len(barcodes) > 0:\n",
    "            return 3, barcodes[0].data.decode('utf-8')\n",
    "        \n",
    "        for i in range(127, 256):  #粗暴的阈值处理（可能先通过某种算法调整对比度）\n",
    "            _, output2 = cv2.threshold(new_img, i, 255, cv2.THRESH_BINARY)\n",
    "            barcodes=pyzbar.decode(output2)\n",
    "            if len(barcodes) != 0:\n",
    "                return 4, barcodes[0].data.decode('utf-8')\n",
    "        else:\n",
    "            # output = fix_img(new_img)\n",
    "            # if output is None:\n",
    "            return -1, ''\n",
    "    return -1, ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'qr'\n",
    "output_file = 'predictions.txt'\n",
    "counter = [0, 0, 0, 0, 0]\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for file_name in tqdm(os.listdir(input_path)):\n",
    "        img = cv2.imread(os.path.join(input_path, file_name))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        status, result = recog_qr(img)\n",
    "        f.write('{} {}\\n'.format(file_name, result))\n",
    "        if status != -1:\n",
    "            counter[status] += 1\n",
    "\n",
    "total = sum(counter)\n",
    "print()\n",
    "print('Sum*', 'Base', 'T-hat', 'lapla', 'athrs', 'thrs', sep='\\t')\n",
    "print(total, *counter, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}