{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_img = \"tickets/0026.bmp\"\n",
    "att_img = cv2.imread(att_img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(att_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = att_img.shape\n",
    "crop_img = att_img[int(r*0.5):r-30, int(c*0.7): c-5] # 裁剪比例，右下角约八分之一\n",
    "\n",
    "plt.imshow(crop_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv2.medianBlur(crop_img, 7)\n",
    "\n",
    "blurred_img = 255 - blurred_img\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "morphed = cv2.morphologyEx(blurred_img, cv2.MORPH_OPEN, kernel)\n",
    "top_hat = 255 - cv2.subtract(blurred_img, morphed)\n",
    "\n",
    "plt.imshow(top_hat, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, thres_img = cv2.threshold(top_hat, np.max(top_hat) * 0.5, 255, cv2.THRESH_BINARY)\n",
    "# thres_img = cv2.adaptiveThreshold(top_hat, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "morphed_img = cv2.morphologyEx(top_hat, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "morphed_img = cv2.morphologyEx(morphed_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "_, morphed_img = cv2.threshold(morphed_img, np.max(morphed_img) * 0.8, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "morphed_img = np.pad(morphed_img, ((0, 2), (0, 2)),'constant', constant_values=(255,255))\n",
    "\n",
    "plt.imshow(morphed_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(morphed_img, 80, 150)\n",
    "\n",
    "contour_img = cv2.cvtColor(crop_img, cv2.COLOR_GRAY2BGR)\n",
    "contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour_img = cv2.drawContours(contour_img, contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "plt.imshow(canny, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_contour ,max_area = 0, 0\n",
    "for contour in contours:\n",
    "    tmp = cv2.contourArea(contour)\n",
    "    if tmp > max_area:\n",
    "        max_contour, max_area = contour, tmp\n",
    "\n",
    "max_contour = max_contour.squeeze()\n",
    "maxx, maxy = np.max(max_contour, axis=0) + 8\n",
    "minx, miny = np.min(max_contour, axis=0) - 8\n",
    "print(minx, maxx, miny, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lines = cv2.HoughLines(canny, 1, np.pi / 180, 10) # 参数\n",
    "# lines = lines.squeeze()\n",
    "# print(lines.shape)\n",
    "\n",
    "# fetch_lines = fetch_line(lines)\n",
    "# left, right, up, down = *fetch_lines[0], *fetch_lines[1]\n",
    "\n",
    "res_img = crop_img[miny:maxy, minx:maxx]\n",
    "plt.imshow(res_img, cmap='gray')\n"
   ]
  },
  {
   "source": [
    "--------\n",
    "操作汇总\n",
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从lines中合并出矩形的四条直线\n",
    "# python霍夫变换输出直线的顺序是点从多到少\n",
    "def fetch_line(lines):\n",
    "    lines = abs(lines) # 对rho取绝对值\n",
    "    line_num = 4 # 横竖各考虑2条干扰线，太多会引入误差，太少容易漏掉真边\n",
    "    standard_shape = 90 # 设定二维码标准长宽\n",
    "    fetch_lines = np.zeros((2, line_num)) \n",
    "    cnt = [0, 0]\n",
    "    for rho, theta in lines:\n",
    "        mode = 0\n",
    "        if theta < np.pi / 180 * 5 or np.pi - theta < np.pi / 180 * 5: # 竖线\n",
    "            mode = 0\n",
    "        elif abs(theta - np.pi / 2) < np.pi / 180 * 5: # 横线\n",
    "            mode = 1\n",
    "        else:\n",
    "            continue\n",
    "        if cnt[mode] >= line_num:\n",
    "            continue\n",
    "\n",
    "        for i in range(cnt[mode]):\n",
    "            r = fetch_lines[mode][i]\n",
    "            if abs(rho - r) <= 15: # 认为是同一条线，rho取更外围的值\n",
    "                if rho > canny.shape[0]/2 and rho > r:\n",
    "                    fetch_lines[mode][i] = rho\n",
    "                elif rho < canny.shape[0]/2 and rho < r:\n",
    "                    fetch_lines[mode][i] = rho\n",
    "                break\n",
    "        else:\n",
    "            fetch_lines[mode][cnt[mode]] = rho\n",
    "            cnt[mode] += 1\n",
    "\n",
    "    # 取相邻两边距离最接近standard_shape的一对边\n",
    "    fetch_lines = np.sort(fetch_lines, axis=1)\n",
    "    # print(\"sorted:\", fetch_lines)\n",
    "    result = np.zeros((2, 2))\n",
    "    for mode in range(2):\n",
    "        min = standard_shape\n",
    "        for i in range(line_num):\n",
    "            if fetch_lines[mode, i] == 0: continue\n",
    "            for j in range(i+1, line_num):\n",
    "                dis = fetch_lines[mode, j] - fetch_lines[mode, i] - standard_shape \n",
    "                if dis > 0 and dis < min:\n",
    "                    min = dis\n",
    "                    result[mode] = [fetch_lines[mode, i], fetch_lines[mode, j]]\n",
    "    \n",
    "    # print(result)\n",
    "    return np.uint8(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qr_old(att_img):\n",
    "    # 裁剪，右下角约八分之一\n",
    "    r, c = att_img.shape\n",
    "    crop_img = att_img[int(r*0.5):r-30, int(c*0.7): c-5]\n",
    "\n",
    "    # 滤波、二值化\n",
    "    blurred_img = cv2.medianBlur(crop_img, 7)\n",
    "    _, thres_img = cv2.threshold(blurred_img, max(blurred_img.reshape(-1)) * 0.5, 255, cv2.THRESH_BINARY)  \n",
    "\n",
    "    # 形态学处理\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    morphed_img = cv2.morphologyEx(thres_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))\n",
    "    morphed_img = cv2.morphologyEx(morphed_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # 霍夫变换\n",
    "    canny = cv2.Canny(morphed_img, 80, 150)\n",
    "    lines = cv2.HoughLines(canny, 1, np.pi / 180, 10) # 参数\n",
    "    lines = lines.squeeze()\n",
    "\n",
    "    # 求解四条边界\n",
    "    fetch_lines = fetch_line(lines)\n",
    "    left, right, up, down = *fetch_lines[0], *fetch_lines[1]\n",
    "\n",
    "    res_img = crop_img[up-2:down+2, left-2:right+2]\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qr(att_img, img_name):\n",
    "    # 裁剪，右下角约八分之一\n",
    "    r, c = att_img.shape\n",
    "    crop_img = att_img[int(r*0.5):r-30, int(c*0.7): c-5]\n",
    "\n",
    "    blurred_img = cv2.medianBlur(crop_img, 7)\n",
    "    blurred_img = 255 - blurred_img\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    morphed = cv2.morphologyEx(blurred_img, cv2.MORPH_OPEN, kernel)\n",
    "    top_hat = 255 - cv2.subtract(blurred_img, morphed)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    morphed_img = cv2.morphologyEx(top_hat, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    morphed_img = cv2.morphologyEx(morphed_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    _, morphed_img = cv2.threshold(morphed_img, np.max(morphed_img) * 0.8, 255, cv2.THRESH_BINARY)\n",
    "    morphed_img = np.pad(morphed_img, ((0, 2), (0, 2)),'constant', constant_values=(255,255))\n",
    "\n",
    "    canny = cv2.Canny(morphed_img, 80, 150)\n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_contour ,max_area = 0, 0\n",
    "    for contour in contours:\n",
    "        tmp = cv2.contourArea(contour)\n",
    "        if tmp > max_area:\n",
    "            max_contour, max_area = contour, tmp\n",
    "\n",
    "    max_contour = max_contour.squeeze()\n",
    "    maxx, maxy = np.max(max_contour, axis=0) + 8\n",
    "    minx, miny = np.min(max_contour, axis=0) - 8\n",
    "\n",
    "    res_img = crop_img[miny:maxy, minx:maxx]\n",
    "\n",
    "    if not (res_img.shape[1]>0 and res_img.shape[0] / res_img.shape[1] > 0.9 and res_img.shape[0] / res_img.shape[1] < 1.1):\n",
    "        fail_list.append(img_name)\n",
    "        att2_img = extract_qr_old(att_img)\n",
    "        if att2_img.shape[0]>0 and att2_img.shape[1]>0:\n",
    "            return att2_img\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./tickets\"\n",
    "output_path = \"./qr\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "fail_list = []\n",
    "for file_name in tqdm(os.listdir(input_path)):\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join(input_path, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "        qr_img = extract_qr(img, file_name)\n",
    "        cv2.imwrite(os.path.join(output_path, file_name), qr_img)\n",
    "    except Exception as e:\n",
    "        print(\"\\nFail at {}: {} skipped\".format(file_name, e.args[0]))\n",
    "print('\\ndone!')\n",
    "print('Following pictures were failed with new algorithm. Old algorithm was applied:')\n",
    "for name in fail_list:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv]",
   "language": "python",
   "name": "conda-env-opencv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}